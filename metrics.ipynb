{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "text": [
      "/home/andrey/PycharmProjects/sentences_analysis/venv/lib/python3.8/site-packages/pandas/compat/__init__.py:117: UserWarning: Could not import the lzma module. Your installed Python is incomplete. Attempting to use lzma compression will result in a RuntimeError.\n",
      "  warnings.warn(msg)\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from pymystem3 import Mystem\n",
    "from nltk.corpus import stopwords\n",
    "from string import punctuation\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "import nltk\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Подготовка данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "text": [
      "[nltk_data] Downloading package stopwords to /home/andrey/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "data = pd.read_excel('data/KNN (1-3,5).xlsx') \n",
    "\n",
    "nltk.download(\"stopwords\")\n",
    "russian_stopwords = stopwords.words(\"russian\")\n",
    "mystem = Mystem()\n",
    "\n",
    "def preprocess_sentence(sentence):\n",
    "    tokens = mystem.lemmatize(sentence.lower())\n",
    "    tokens = [token for token in tokens if token not in russian_stopwords\\\n",
    "              and token != \" \" \\\n",
    "              and token.strip() not in punctuation]\n",
    "    \n",
    "    tokenized_sentence = \" \".join(tokens)\n",
    "    return tokenized_sentence \n",
    "\n",
    "emotions_table = {\n",
    "    'восторг': 'восторг',\n",
    "\t'радость': 'восторг',\n",
    "\t'безмятежность': 'восторг',\n",
    "    'восхищение': 'восхищение',\n",
    "\t'доверие': 'восхищение',\n",
    "\t'принятие': 'восхищение',\n",
    "    'ужас': 'ужас',\n",
    "\t'страх': 'ужас',\n",
    "\t'тревога': 'ужас',\n",
    "    'изумление': 'изумление',\n",
    "\t'удивление': 'изумление',\n",
    "\t'возбуждение': 'изумление',\n",
    "    'горе': 'горе',\n",
    "\t'грусть': 'горе',\n",
    "\t'печаль': 'горе',\n",
    "    'отвращение': 'отвращение',\n",
    "\t'неудовольствие': 'отвращение',\n",
    "\t'скука': 'отвращение',\n",
    "    'гнев': 'гнев',\n",
    "\t'злость': 'гнев',\n",
    "\t'досада': 'гнев',\n",
    "    'настороженность': 'настороженность',\n",
    "\t'ожидание': 'настороженность',\n",
    "\t'интерес': 'настороженность',\n",
    "}\n",
    "\n",
    "def normalize_emotion(emotion):\n",
    "    emotion = emotion.lower()\n",
    "    result = emotions_table.get(emotion)\n",
    "    assert result is not None, f\"Emotion '{emotion}' is not correct one.\"\n",
    "    return result.lower()\n",
    "\n",
    "def preprocess_sentence(sentence):\n",
    "    tokens = mystem.lemmatize(sentence.lower())\n",
    "    tokens = [token for token in tokens if token not in russian_stopwords\\\n",
    "              and token != \" \" \\\n",
    "              and token.strip() not in punctuation]\n",
    "    \n",
    "    tokenized_sentence = \" \".join(tokens)\n",
    "    return tokenized_sentence  \n",
    "\n",
    "processed_sentences = list(map(preprocess_sentence, data['Предложение']))\n",
    "temp = pd.DataFrame(columns=['Предложение', 'Эмоция'])\n",
    "\n",
    "for i, (emotion, sentence) in enumerate(zip(data['Эмоция'], processed_sentences)):\n",
    "    if any(delim in emotion for delim in (' ', ',', '.', '\\n')):\n",
    "        emotions = [normalize_emotion(e) for e in re.split('[ ,.\\n]', emotion.strip()) if e != '']\n",
    "        # for e in emotions:\n",
    "        #     temp = temp.append({'Предложение': sentence, 'Эмоция': e}, ignore_index=True)\n",
    "        temp = temp.append({'Предложение': sentence, 'Эмоция': emotions[0]}, ignore_index=True)\n",
    "    else:\n",
    "        temp = temp.append({'Предложение': sentence, 'Эмоция': normalize_emotion(emotion)}, ignore_index=True)\n",
    "\n",
    "processed_data = temp\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Analysis\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.1 Trying with CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "vectorizer_count = CountVectorizer()\n",
    "# tokenize and build vocab\n",
    "vectorizer_count.fit(processed_data['Предложение'])\n",
    "count_vec_matrix = vectorizer_count.transform(processed_data['Предложение'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## №4. Классификация"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from typing import List, Iterable, Dict, Tuple\n",
    "\n",
    "import collections\n",
    "import itertools\n",
    "import scipy\n",
    "import time\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "\n",
    "from nltk.stem.snowball import RussianStemmer\n",
    "stemmer = RussianStemmer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1 Обучение классификатора \n",
    "Строим модели с разнами разбиениями датасета и разными k для KNN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "DEFAULT_COLORS = ['red', 'green', 'orange', 'purple', 'blue', 'gray', 'pink']\n",
    "DEFAULT_SPLITS = [0.20, 0.30, 0.40, 0.50]\n",
    "\n",
    "def get_colors(n):\n",
    "  colors = DEFAULT_COLORS[:n]\n",
    "  if n > len(DEFAULT_COLORS):\n",
    "    import matplotlib, random\n",
    "    all_colours = matplotlib.colors.get_named_colors_mapping()\n",
    "    colors.extend(random.choices(all_colours, k=n-len(DEFAULT_COLORS)))\n",
    "  return colors\n",
    "\n",
    "def _knn_analysis(X, y, splits, k_interval) -> Tuple[List[List[float]], List[List[float]], Dict[str, int]]:\n",
    "  error_over_splits_train = []\n",
    "  error_over_splits_test = []\n",
    "  best_result = {'split': 0, 'k': 0, 'error': 1}\n",
    "  for split in splits:\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=split)\n",
    "    #---------------------\n",
    "    # here could be scaler\n",
    "    #---------------------\n",
    "    # Comparing Error Rate with the K Value\n",
    "    # (calculating error for K values in k_range)\n",
    "    error_for_one_split = []\n",
    "    \n",
    "    err_one_split_test = []\n",
    "    err_one_split_train = []\n",
    "    \n",
    "    for i in k_interval:\n",
    "        knn = KNeighborsClassifier(n_neighbors=i)\n",
    "        knn.fit(X_train, y_train)\n",
    "        \n",
    "        y_train_predict = knn.predict(X_train)\n",
    "        y_test_predict = knn.predict(X_test)\n",
    "        \n",
    "        err_train_tmp = np.mean(y_train != y_train_predict)\n",
    "        err_test_tmp = np.mean(y_test != y_test_predict)\n",
    "        \n",
    "        err_one_split_test.append(err_test_tmp)\n",
    "        err_one_split_train.append(err_train_tmp)\n",
    "        \n",
    "        # check the best result\n",
    "        if err_test_tmp < best_result['error']:\n",
    "            best_result['split'] = split\n",
    "            best_result['k'] = i\n",
    "            best_result['error'] = err_test_tmp\n",
    "    error_over_splits_train.append(err_one_split_train)\n",
    "    error_over_splits_test.append(err_one_split_test)\n",
    "  return error_over_splits_train, error_over_splits_test, best_result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 Визуализация результатов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def visualize_knn_analysis(X, y, splits=None, min_k=1, max_k=40):\n",
    "  if not splits:\n",
    "    splits = DEFAULT_SPLITS\n",
    "  k_range = range(min_k, max_k+1)\n",
    "  \n",
    "  # Training and Predictions\n",
    "  errors_over_splits_train, errors_over_splits_test, best_res = _knn_analysis(X, y, splits, k_range)\n",
    "          \n",
    "  # Plot results\n",
    "  plt.figure(num=1, figsize=(12, 6))\n",
    "  for test_size, errors_on_split, color in zip(splits, errors_over_splits_train, get_colors(len(splits))):\n",
    "    label_name = str(int(test_size * 100)) + '%/'+ str(int((1 - test_size) * 100)) + '%'\n",
    "    plt.plot(k_range, errors_on_split, color=color, marker='o', markerfacecolor='blue', markersize=2, label=label_name)\n",
    "\n",
    "  plt.title('Error Rate K Value')\n",
    "  plt.xlabel('K Value')\n",
    "  plt.ylabel('Mean Train Error')\n",
    "  plt.legend(loc='best')\n",
    "  \n",
    "  plt.figure(num=2, figsize=(12, 6))\n",
    "  for test_size, errors_on_split, color in zip(splits, errors_over_splits_test, get_colors(len(splits))):\n",
    "    label_name = str(int(test_size * 100)) + '%/'+ str(int((1 - test_size) * 100)) + '%'\n",
    "    plt.plot(k_range, errors_on_split, color=color, marker='o', markerfacecolor='blue', markersize=2, label=label_name)\n",
    "  plt.title('Error Rate K Value')\n",
    "  plt.xlabel('K Value')\n",
    "  plt.ylabel('Mean Test Error')\n",
    "  plt.legend(loc='best')\n",
    "  \n",
    "  print(\"Best set:\")\n",
    "  print(\"Split: \" + str(int((1 - best_res['split']) * 100)) + '%/' + str(int(best_res['split'] * 100)) + '%')\n",
    "  print(\"K: \" + str(best_res['k']))\n",
    "  print(\"Error value: \" + str(best_res['error']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3 Оптимизация пространства признаков"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def feature_optimize(X:scipy.sparse.csr_matrix, vectorizer, comparator, *, stemming=False, debug=False, **kwargs) -> scipy.sparse.csr_matrix:\n",
    "  df = pd.DataFrame(X.toarray(), columns=vectorizer.vocabulary_)\n",
    "  if debug:\n",
    "    print(f'Columns before: {len(df.columns)}')\n",
    "\n",
    "  # getting similar columns\n",
    "  start = time.time()\n",
    "  similar_col_groups = collections.defaultdict(set)\n",
    "  if stemming:\n",
    "    words_and_stems = {w: stemmer.stem(w) for w in df.columns}\n",
    "    df = df.groupby(level=0, axis=1).sum()\n",
    "  words = list(df.columns)\n",
    "  for i, (w1, w2) in enumerate(filter(lambda word_pair: comparator(*word_pair, **kwargs), \n",
    "                                      itertools.combinations(words, 2)), 1):\n",
    "    similar_col_groups[w1].add(w2)\n",
    "    similar_col_groups[w2].add(w1)\n",
    "    if debug:\n",
    "      if i % 1000 == 0:\n",
    "        print(f\"{i} entries are matched by comparator\")\n",
    "  if debug:\n",
    "    print('PROCESSING TIME:', time.time() - start)\n",
    "    print(f'Got similar_col_groups (len: {len(similar_col_groups)})')\n",
    "  \n",
    "  _merge_intersecting_groups(similar_col_groups)\n",
    "  if debug:\n",
    "    print('Groups after merging:', len(similar_col_groups))\n",
    "\n",
    "  df = join_columns(similar_col_groups.items(), df, debug)\n",
    "  if debug:\n",
    "    print(f'Columns after: {len(df.columns)}')\n",
    "  return scipy.sparse.csr_matrix(df.values)\n",
    "\n",
    "def _merge_intersecting_groups(similar_col_groups):\n",
    "  def merge_subkeys_into_group(main_key, group, subkeys=None):\n",
    "    if subkeys is None:\n",
    "      subkeys = set(group)\n",
    "    else:\n",
    "      group.update(subkeys)\n",
    "    for key in subkeys:\n",
    "      if key in similar_col_groups:\n",
    "        new_keys = similar_col_groups[key] - group - {key, main_key}\n",
    "        if len(new_keys) > 0:\n",
    "          merge_subkeys_into_group(main_key, group, new_keys)\n",
    "        del similar_col_groups[key]\n",
    "  for key in tuple(similar_col_groups.keys()):\n",
    "    if key in similar_col_groups:\n",
    "      group = similar_col_groups[key]\n",
    "      merge_subkeys_into_group(key, group)\n",
    "      \n",
    "def join_columns(column_groups: Iterable[Tuple[str, Iterable[str]]], df: pd.DataFrame, debug) -> pd.DataFrame:\n",
    "  if debug:\n",
    "    print('DF in \"join_columns\":\\n', df)\n",
    "  for key, group in column_groups:\n",
    "    for subkey in group:\n",
    "      if subkey in df.columns:\n",
    "        try:\n",
    "          df[key] += df[subkey]\n",
    "        except Exception as e:\n",
    "          rendered_cols = \", \".join(f\"'{col_name}\" for col_name in df.columns)\n",
    "          rendered_group = \", \".join(f\"'{k}'\" for k in group)\n",
    "          print(f\"key: '{key}'; subkey '{subkey}' [cols: {rendered_cols}] [group: {rendered_group}]\")\n",
    "          print(f\"df[key]: {df[key]}; df[subkey]: {df[subkey]}\")\n",
    "          exit('ERROR')\n",
    "        del df[subkey]\n",
    "      elif debug:\n",
    "        rendered_cols = \", \".join(f\"'{col_name}\" for col_name in df.columns)\n",
    "        rendered_group = \", \".join(f\"'{k}'\" for k in group)\n",
    "        print(f\"key: '{key}'; subkey '{subkey}' do not exist in DF [cols: {rendered_cols}] [group: {rendered_group}]\")\n",
    "  return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## №5. Анализ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **5.1 Bag-of-Words + KNN**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Baseline**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "X = count_vec_matrix\n",
    "y = processed_data['Эмоция'].to_numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Анализ результатов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score, roc_auc_score, average_precision_score, log_loss\n",
    "from sklearn.preprocessing import MultiLabelBinarizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# classes = ['гнев', 'отвращение', 'горе', 'изумление', 'ужас', 'восхищение', 'восторг', 'настроженность']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, stratify=y)\n",
    "knn = KNeighborsClassifier(n_neighbors=15)\n",
    "knn.fit(X_train, y_train)\n",
    "knn_probs = knn.predict_proba(X_test)\n",
    "classes = knn.classes_\n",
    "y_pred = knn.predict(X_test)\n",
    "\n",
    "mlb = MultiLabelBinarizer(classes=classes)\n",
    "y_test_bin = mlb.fit_transform([[x] for x in y_test])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Классические бинарные метрики, баланс классов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "                 precision    recall  f1-score   support\n",
      "\n",
      "        восторг       0.00      0.00      0.00         8\n",
      "     восхищение       0.00      0.00      0.00         6\n",
      "           гнев       0.15      0.93      0.27        14\n",
      "           горе       0.00      0.00      0.00        12\n",
      "      изумление       0.00      0.00      0.00        12\n",
      "настороженность       1.00      0.17      0.29         6\n",
      "     отвращение       0.00      0.00      0.00         9\n",
      "           ужас       0.00      0.00      0.00        23\n",
      "\n",
      "       accuracy                           0.16        90\n",
      "      macro avg       0.14      0.14      0.07        90\n",
      "   weighted avg       0.09      0.16      0.06        90\n",
      "\n"
     ],
     "output_type": "stream"
    },
    {
     "data": {
      "text/plain": "<Figure size 720x432 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "report_table = classification_report(y_test, knn.predict(X_test), target_names=classes)\n",
    "print(report_table)\n",
    "\n",
    "report_dict = classification_report(y_test, y_pred, target_names=classes, output_dict=True)\n",
    "\n",
    "fig = plt.figure(figsize=(10,6))\n",
    "ax = fig.add_axes([0,0,1,1])\n",
    "support = [report_dict[label]['support'] for label in classes]\n",
    "ax.bar(classes, support)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Метрики качества многоклассовой классификации: микро- и макро-усреднение"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-55-4a09aeea83e3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmicro\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf1_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mknn_probs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maverage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'micro'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mmacro\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf1_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mknn_probs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maverage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'macro'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Micro: \"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmicro\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Micro: \"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmacro\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/PycharmProjects/sentences_analysis/venv/lib/python3.8/site-packages/sklearn/metrics/_classification.py\u001b[0m in \u001b[0;36mf1_score\u001b[0;34m(y_true, y_pred, labels, pos_label, average, sample_weight, zero_division)\u001b[0m\n\u001b[1;32m   1094\u001b[0m     \u001b[0mmodified\u001b[0m \u001b[0;32mwith\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mzero_division\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1095\u001b[0m     \"\"\"\n\u001b[0;32m-> 1096\u001b[0;31m     return fbeta_score(y_true, y_pred, 1, labels=labels,\n\u001b[0m\u001b[1;32m   1097\u001b[0m                        \u001b[0mpos_label\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpos_label\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maverage\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maverage\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1098\u001b[0m                        \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/PycharmProjects/sentences_analysis/venv/lib/python3.8/site-packages/sklearn/metrics/_classification.py\u001b[0m in \u001b[0;36mfbeta_score\u001b[0;34m(y_true, y_pred, beta, labels, pos_label, average, sample_weight, zero_division)\u001b[0m\n\u001b[1;32m   1217\u001b[0m     \"\"\"\n\u001b[1;32m   1218\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1219\u001b[0;31m     _, _, f, _ = precision_recall_fscore_support(y_true, y_pred,\n\u001b[0m\u001b[1;32m   1220\u001b[0m                                                  \u001b[0mbeta\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbeta\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1221\u001b[0m                                                  \u001b[0mlabels\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/PycharmProjects/sentences_analysis/venv/lib/python3.8/site-packages/sklearn/metrics/_classification.py\u001b[0m in \u001b[0;36mprecision_recall_fscore_support\u001b[0;34m(y_true, y_pred, beta, labels, pos_label, average, warn_for, sample_weight, zero_division)\u001b[0m\n\u001b[1;32m   1481\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mbeta\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1482\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"beta should be >=0 in the F-beta score\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1483\u001b[0;31m     labels = _check_set_wise_labels(y_true, y_pred, average, labels,\n\u001b[0m\u001b[1;32m   1484\u001b[0m                                     pos_label)\n\u001b[1;32m   1485\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/PycharmProjects/sentences_analysis/venv/lib/python3.8/site-packages/sklearn/metrics/_classification.py\u001b[0m in \u001b[0;36m_check_set_wise_labels\u001b[0;34m(y_true, y_pred, average, labels, pos_label)\u001b[0m\n\u001b[1;32m   1299\u001b[0m                          str(average_options))\n\u001b[1;32m   1300\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1301\u001b[0;31m     \u001b[0my_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_check_targets\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1302\u001b[0m     \u001b[0mpresent_labels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0munique_labels\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1303\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0maverage\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'binary'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/PycharmProjects/sentences_analysis/venv/lib/python3.8/site-packages/sklearn/metrics/_classification.py\u001b[0m in \u001b[0;36m_check_targets\u001b[0;34m(y_true, y_pred)\u001b[0m\n\u001b[1;32m     87\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_type\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 89\u001b[0;31m         raise ValueError(\"Classification metrics can't handle a mix of {0} \"\n\u001b[0m\u001b[1;32m     90\u001b[0m                          \"and {1} targets\".format(type_true, type_pred))\n\u001b[1;32m     91\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Classification metrics can't handle a mix of multiclass and continuous-multioutput targets"
     ],
     "ename": "ValueError",
     "evalue": "Classification metrics can't handle a mix of multiclass and continuous-multioutput targets",
     "output_type": "error"
    }
   ],
   "source": [
    "micro = f1_score(y_test, y_pred, average = 'micro')\n",
    "macro = f1_score(y_test, y_pred, average = 'macro')\n",
    "print(\"Micro: \", micro)\n",
    "print(\"Micro: \", macro)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Метрики качества: AUC-ROC, AUC-PR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "AUC-ROC:  0.5316564015883408\n",
      "AUC-PR:  0.19679688222536784\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "roc_auc = roc_auc_score(y_test_bin, knn_probs)\n",
    "aps = average_precision_score(y_test_bin, knn_probs)\n",
    "print(\"AUC-ROC: \", roc_auc)\n",
    "print(\"AUC-PR: \", aps)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Метрики качества: logloss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "log-loss:  4.813542741210963\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "# print(mlb.fit_transform([[x] for x in y_test]))\n",
    "\n",
    "\n",
    "ll = log_loss(y_test_bin, knn_probs)\n",
    "print(\"log-loss: \", ll)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "source": [],
    "metadata": {
     "collapsed": false
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}